{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment below line of code if you want to calculate features and save dataframe\n",
    "# this script prints the path at which dataframe with calculated features is saved.\n",
    "# train.py calls the DataGenerator class to \n",
    "\n",
    "# %run ./train.py WMT original\n",
    "\n",
    "# this notebook was trained on cloud compute. So use your own paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "",
    "_uuid": "",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>rsi_6</th>\n",
       "      <th>rsi_7</th>\n",
       "      <th>rsi_8</th>\n",
       "      <th>...</th>\n",
       "      <th>eom_19</th>\n",
       "      <th>eom_20</th>\n",
       "      <th>eom_21</th>\n",
       "      <th>eom_22</th>\n",
       "      <th>eom_23</th>\n",
       "      <th>eom_24</th>\n",
       "      <th>eom_25</th>\n",
       "      <th>eom_26</th>\n",
       "      <th>volume_delta</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-02-24</td>\n",
       "      <td>47.00</td>\n",
       "      <td>47.88</td>\n",
       "      <td>43.44</td>\n",
       "      <td>47.88</td>\n",
       "      <td>33.2525</td>\n",
       "      <td>19431900</td>\n",
       "      <td>10.484813</td>\n",
       "      <td>25.636878</td>\n",
       "      <td>24.162837</td>\n",
       "      <td>...</td>\n",
       "      <td>-44.898337</td>\n",
       "      <td>-44.898337</td>\n",
       "      <td>-44.898337</td>\n",
       "      <td>-44.898337</td>\n",
       "      <td>-44.898337</td>\n",
       "      <td>-44.898337</td>\n",
       "      <td>-44.898337</td>\n",
       "      <td>-44.898337</td>\n",
       "      <td>6557500.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-02-25</td>\n",
       "      <td>44.31</td>\n",
       "      <td>45.31</td>\n",
       "      <td>43.63</td>\n",
       "      <td>44.50</td>\n",
       "      <td>30.9051</td>\n",
       "      <td>16908500</td>\n",
       "      <td>7.546718</td>\n",
       "      <td>7.215117</td>\n",
       "      <td>20.195163</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.823639</td>\n",
       "      <td>-11.823639</td>\n",
       "      <td>-11.823639</td>\n",
       "      <td>-11.823639</td>\n",
       "      <td>-11.823639</td>\n",
       "      <td>-11.823639</td>\n",
       "      <td>-11.823639</td>\n",
       "      <td>-11.823639</td>\n",
       "      <td>-2523400.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-02-28</td>\n",
       "      <td>44.56</td>\n",
       "      <td>46.94</td>\n",
       "      <td>44.56</td>\n",
       "      <td>46.19</td>\n",
       "      <td>32.0788</td>\n",
       "      <td>17836100</td>\n",
       "      <td>25.691514</td>\n",
       "      <td>17.962019</td>\n",
       "      <td>16.947352</td>\n",
       "      <td>...</td>\n",
       "      <td>17.079967</td>\n",
       "      <td>17.079967</td>\n",
       "      <td>17.079967</td>\n",
       "      <td>17.079967</td>\n",
       "      <td>17.079967</td>\n",
       "      <td>17.079967</td>\n",
       "      <td>17.079967</td>\n",
       "      <td>17.079967</td>\n",
       "      <td>927600.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-02-29</td>\n",
       "      <td>47.94</td>\n",
       "      <td>49.75</td>\n",
       "      <td>47.94</td>\n",
       "      <td>48.75</td>\n",
       "      <td>33.8567</td>\n",
       "      <td>17197200</td>\n",
       "      <td>53.950905</td>\n",
       "      <td>38.433319</td>\n",
       "      <td>28.473520</td>\n",
       "      <td>...</td>\n",
       "      <td>32.574780</td>\n",
       "      <td>32.574780</td>\n",
       "      <td>32.574780</td>\n",
       "      <td>32.574780</td>\n",
       "      <td>32.574780</td>\n",
       "      <td>32.574780</td>\n",
       "      <td>32.574780</td>\n",
       "      <td>32.574780</td>\n",
       "      <td>-638900.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>49.88</td>\n",
       "      <td>50.00</td>\n",
       "      <td>47.50</td>\n",
       "      <td>49.00</td>\n",
       "      <td>34.0303</td>\n",
       "      <td>10165800</td>\n",
       "      <td>56.298450</td>\n",
       "      <td>53.023610</td>\n",
       "      <td>37.866343</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.336265</td>\n",
       "      <td>-2.336265</td>\n",
       "      <td>-2.336265</td>\n",
       "      <td>-2.336265</td>\n",
       "      <td>-2.336265</td>\n",
       "      <td>-2.336265</td>\n",
       "      <td>-2.336265</td>\n",
       "      <td>-2.336265</td>\n",
       "      <td>-7031400.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 450 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp   open   high    low  close  adjusted_close    volume  \\\n",
       "0  2000-02-24  47.00  47.88  43.44  47.88         33.2525  19431900   \n",
       "1  2000-02-25  44.31  45.31  43.63  44.50         30.9051  16908500   \n",
       "2  2000-02-28  44.56  46.94  44.56  46.19         32.0788  17836100   \n",
       "3  2000-02-29  47.94  49.75  47.94  48.75         33.8567  17197200   \n",
       "4  2000-03-01  49.88  50.00  47.50  49.00         34.0303  10165800   \n",
       "\n",
       "       rsi_6      rsi_7      rsi_8  ...     eom_19     eom_20     eom_21  \\\n",
       "0  10.484813  25.636878  24.162837  ... -44.898337 -44.898337 -44.898337   \n",
       "1   7.546718   7.215117  20.195163  ... -11.823639 -11.823639 -11.823639   \n",
       "2  25.691514  17.962019  16.947352  ...  17.079967  17.079967  17.079967   \n",
       "3  53.950905  38.433319  28.473520  ...  32.574780  32.574780  32.574780   \n",
       "4  56.298450  53.023610  37.866343  ...  -2.336265  -2.336265  -2.336265   \n",
       "\n",
       "      eom_22     eom_23     eom_24     eom_25     eom_26  volume_delta  labels  \n",
       "0 -44.898337 -44.898337 -44.898337 -44.898337 -44.898337     6557500.0       2  \n",
       "1 -11.823639 -11.823639 -11.823639 -11.823639 -11.823639    -2523400.0       1  \n",
       "2  17.079967  17.079967  17.079967  17.079967  17.079967      927600.0       2  \n",
       "3  32.574780  32.574780  32.574780  32.574780  32.574780     -638900.0       2  \n",
       "4  -2.336265  -2.336265  -2.336265  -2.336265  -2.336265    -7031400.0       2  \n",
       "\n",
       "[5 rows x 450 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle \n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "company_code = 'WMT'\n",
    "strategy_type = 'original'\n",
    "# use the path printed in above output cell after running stock_cnn.py. It's in below format\n",
    "df = pd.read_csv(\"../outputs/fresh_rolling_train/df_\"+company_code+\".csv\")\n",
    "df['labels'] = df['labels'].astype(np.int8)\n",
    "if 'dividend_amount' in df.columns:\n",
    "    df.drop(columns=['dividend_amount', 'split_coefficient'], inplace=True)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into Training, Validation and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features 447\n",
      "train_split = 0.7\n",
      "Shape of x, y train/cv/test (2797, 447) (2797,) (1200, 447) (1200,) (1000, 447) (1000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "list_features = list(df.loc[:, 'open':'eom_26'].columns)\n",
    "print('Total number of features', len(list_features))\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.loc[:, 'open':'eom_26'].values, df['labels'].values, train_size=0.8, \n",
    "                                                    test_size=0.2, random_state=2, shuffle=True, stratify=df['labels'].values)\n",
    "\n",
    "# smote = RandomOverSampler(random_state=42, sampling_strategy='not majority')\n",
    "# x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "# print('Resampled dataset shape %s' % Counter(y_train))\n",
    "\n",
    "if 0.7*x_train.shape[0] < 2500:\n",
    "    train_split = 0.8\n",
    "else:\n",
    "    train_split = 0.7\n",
    "# train_split = 0.7\n",
    "print('train_split =',train_split)\n",
    "x_train, x_cv, y_train, y_cv = train_test_split(x_train, y_train, train_size=train_split, test_size=1-train_split, \n",
    "                                                random_state=2, shuffle=True, stratify=y_train)\n",
    "mm_scaler = MinMaxScaler(feature_range=(0, 1)) # or StandardScaler?\n",
    "x_train = mm_scaler.fit_transform(x_train)\n",
    "x_cv = mm_scaler.transform(x_cv)\n",
    "x_test = mm_scaler.transform(x_test)\n",
    "\n",
    "x_main = x_train.copy()\n",
    "print(\"Shape of x, y train/cv/test {} {} {} {} {} {}\".format(x_train.shape, y_train.shape, x_cv.shape, y_cv.shape, x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of total 441+ features select top 'N' features (let's include base features like close, adjusted_close etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 225  # should be a perfect square\n",
    "selection_method = 'all'\n",
    "topk = 320 if selection_method == 'all' else num_features\n",
    "# if train_split >= 0.8:\n",
    "#     topk = 400\n",
    "# else:\n",
    "#     topk = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('open', 'high', 'low', 'close', 'adjusted_close', 'volume', 'rsi_6', 'rsi_7', 'rsi_8', 'rsi_9', 'rsi_10', 'rsi_11', 'rsi_12', 'rsi_13', 'rsi_14', 'rsi_15', 'rsi_16', 'rsi_17', 'rsi_18', 'rsi_19', 'rsi_20', 'rsi_21', 'rsi_22', 'rsi_23', 'rsi_24', 'rsi_25', 'rsi_26', 'wr_6', 'wr_7', 'wr_8', 'wr_9', 'wr_10', 'wr_11', 'wr_12', 'wr_13', 'wr_14', 'wr_15', 'wr_16', 'wr_17', 'wr_18', 'wr_19', 'wr_20', 'wr_21', 'wr_22', 'wr_23', 'wr_24', 'wr_25', 'wr_26', 'mfi_6', 'mfi_7', 'mfi_8', 'mfi_9', 'mfi_10', 'mfi_11', 'mfi_12', 'mfi_13', 'mfi_14', 'mfi_15', 'mfi_16', 'mfi_17', 'mfi_18', 'mfi_19', 'mfi_20', 'mfi_21', 'mfi_22', 'mfi_23', 'mfi_24', 'mfi_25', 'mfi_26', 'roc_6', 'roc_7', 'roc_8', 'roc_9', 'roc_10', 'roc_11', 'roc_12', 'roc_13', 'roc_14', 'roc_15', 'roc_16', 'roc_17', 'roc_18', 'roc_19', 'roc_20', 'roc_21', 'roc_22', 'roc_23', 'roc_24', 'roc_25', 'roc_26', 'cmf_6', 'cmf_7', 'cmf_8', 'cmf_9', 'cmf_10', 'cmf_11', 'cmf_12', 'cmf_13', 'cmf_14', 'cmf_15', 'cmf_16', 'cmf_17', 'cmf_18', 'cmf_19', 'cmf_20', 'cmf_21', 'cmf_22', 'cmf_23', 'cmf_24', 'cmf_25', 'cmf_26', 'cmo_6', 'cmo_7', 'cmo_8', 'cmo_9', 'cmo_10', 'cmo_11', 'cmo_12', 'cmo_13', 'cmo_14', 'cmo_15', 'cmo_16', 'cmo_17', 'cmo_18', 'cmo_19', 'cmo_20', 'cmo_21', 'cmo_22', 'cmo_23', 'cmo_24', 'cmo_25', 'cmo_26', 'wma_6', 'hma_0', 'hma_1', 'hma_2', 'hma_3', 'hma_4', 'hma_6', 'trix_6', 'trix_7', 'trix_8', 'trix_9', 'trix_10', 'trix_11', 'trix_12', 'trix_13', 'trix_14', 'trix_15', 'trix_16', 'trix_17', 'trix_18', 'cci_6', 'cci_7', 'cci_8', 'cci_9', 'cci_10', 'cci_11', 'cci_12', 'cci_13', 'cci_14', 'cci_15', 'cci_16', 'cci_17', 'cci_18', 'cci_19', 'cci_20', 'cci_21', 'cci_22', 'cci_23', 'cci_24', 'cci_25', 'cci_26', 'dpo_6', 'dpo_7', 'dpo_8', 'dpo_9', 'dpo_10', 'dpo_11', 'dpo_12', 'dpo_13', 'dpo_14', 'dpo_15', 'dpo_16', 'dpo_17', 'dpo_18', 'dpo_19', 'dpo_20', 'dpo_21', 'dpo_22', 'dpo_23', 'dpo_24', 'dpo_25', 'dpo_26', 'kst_6', 'kst_7', 'kst_8', 'kst_9', 'kst_10', 'kst_11', 'kst_12', 'kst_13', 'kst_14', 'kst_15', 'kst_16', 'kst_17', 'kst_18', 'kst_19', 'kst_20', 'kst_21', 'kst_22', 'kst_23', 'kst_24', 'kst_25', 'kst_26', 'dmi_6', 'dmi_7', 'dmi_8', 'dmi_9', 'dmi_10', 'dmi_11', 'dmi_12', 'dmi_13', 'dmi_14', 'dmi_15', 'dmi_16', 'dmi_17', 'dmi_18', 'dmi_19', 'dmi_20', 'dmi_21', 'dmi_22', 'dmi_23', 'dmi_24', 'dmi_25', 'dmi_26', 'fi_6', 'fi_7', 'fi_8', 'fi_9', 'fi_10', 'fi_11', 'fi_12', 'fi_13', 'fi_14', 'fi_15', 'fi_16', 'fi_17', 'fi_18', 'fi_19', 'fi_20', 'fi_21', 'fi_22', 'fi_23', 'fi_24', 'fi_25', 'fi_26', 'rsv_6', 'kdjk_6', 'rsv_7', 'kdjk_7', 'rsv_8', 'kdjk_8', 'rsv_9', 'kdjk_9', 'rsv_10', 'kdjk_10', 'rsv_11', 'kdjk_11', 'rsv_12', 'kdjk_12', 'rsv_13', 'kdjk_13', 'rsv_14', 'kdjk_14', 'rsv_15', 'kdjk_15', 'rsv_16', 'kdjk_16', 'rsv_17', 'kdjk_17', 'rsv_18', 'kdjk_18', 'rsv_19', 'kdjk_19', 'rsv_20', 'kdjk_20', 'rsv_21', 'kdjk_21', 'rsv_22', 'kdjk_22', 'rsv_23', 'kdjk_23', 'rsv_24', 'kdjk_24', 'rsv_25', 'kdjk_25', 'rsv_26', 'kdjk_26', 'eom_6', 'eom_7', 'eom_8', 'eom_9', 'eom_10', 'eom_11', 'eom_12', 'eom_13', 'eom_14', 'eom_15', 'eom_16', 'eom_17', 'eom_18', 'eom_19', 'eom_20', 'eom_21', 'eom_22', 'eom_23', 'eom_24', 'eom_25', 'eom_26')\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 195 216 217 218 219 220 222 237 238 239 240 241\n",
      " 242 243 244 245 246 247 248 249 258 259 260 261 262 263 264 265 266 267\n",
      " 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285\n",
      " 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303\n",
      " 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321\n",
      " 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339\n",
      " 340 341 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378\n",
      " 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396\n",
      " 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414\n",
      " 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432\n",
      " 433 434 435 436 437 438 439 440 441 442 443 444 445 446]\n",
      "****************************************\n",
      "320 ('high', 'low', 'close', 'adjusted_close', 'volume', 'rsi_6', 'rsi_7', 'rsi_8', 'rsi_9', 'rsi_10', 'rsi_11', 'rsi_12', 'rsi_13', 'rsi_14', 'rsi_15', 'rsi_16', 'rsi_17', 'rsi_18', 'rsi_19', 'rsi_20', 'rsi_21', 'rsi_22', 'rsi_23', 'rsi_24', 'rsi_25', 'rsi_26', 'wr_6', 'wr_7', 'wr_8', 'wr_9', 'wr_10', 'wr_11', 'wr_12', 'wr_13', 'wr_14', 'wr_15', 'wr_16', 'wr_17', 'wr_18', 'wr_19', 'wr_20', 'wr_21', 'wr_22', 'wr_23', 'wr_24', 'wr_25', 'wr_26', 'mfi_6', 'mfi_7', 'mfi_8', 'mfi_9', 'mfi_10', 'mfi_11', 'mfi_12', 'mfi_13', 'mfi_14', 'mfi_15', 'mfi_16', 'mfi_17', 'mfi_18', 'mfi_19', 'mfi_20', 'mfi_21', 'mfi_22', 'mfi_23', 'mfi_24', 'mfi_25', 'mfi_26', 'roc_6', 'roc_7', 'roc_8', 'roc_9', 'roc_10', 'roc_11', 'roc_12', 'roc_13', 'roc_14', 'roc_15', 'roc_16', 'roc_17', 'roc_18', 'roc_19', 'roc_20', 'roc_21', 'roc_22', 'roc_23', 'roc_24', 'roc_25', 'roc_26', 'cmf_6', 'cmf_7', 'cmf_8', 'cmf_9', 'cmf_10', 'cmf_11', 'cmf_12', 'cmf_13', 'cmf_14', 'cmf_15', 'cmf_16', 'cmf_18', 'cmf_19', 'cmf_20', 'cmf_21', 'cmf_22', 'cmf_23', 'cmf_24', 'cmf_25', 'cmf_26', 'cmo_6', 'cmo_7', 'cmo_8', 'cmo_9', 'cmo_10', 'cmo_11', 'cmo_12', 'cmo_13', 'cmo_14', 'cmo_15', 'cmo_16', 'cmo_17', 'cmo_18', 'cmo_19', 'cmo_20', 'cmo_21', 'cmo_22', 'cmo_23', 'cmo_24', 'cmo_25', 'cmo_26', 'close_sma_6', 'open_sma_7', 'open_sma_13', 'open_sma_14', 'wma_23', 'hma_2', 'hma_5', 'hma_7', 'hma_8', 'hma_13', 'trix_6', 'trix_8', 'trix_9', 'trix_11', 'trix_12', 'trix_17', 'trix_18', 'trix_19', 'trix_21', 'trix_22', 'trix_23', 'trix_25', 'cci_6', 'cci_7', 'cci_8', 'cci_9', 'cci_10', 'cci_11', 'cci_12', 'cci_13', 'cci_14', 'cci_15', 'cci_16', 'cci_17', 'cci_18', 'cci_19', 'cci_20', 'cci_21', 'cci_22', 'cci_23', 'cci_24', 'cci_25', 'cci_26', 'dpo_6', 'dpo_7', 'dpo_8', 'dpo_9', 'dpo_10', 'dpo_11', 'dpo_12', 'dpo_13', 'dpo_14', 'dpo_16', 'dpo_17', 'dpo_18', 'dpo_19', 'dpo_20', 'dpo_23', 'dpo_26', 'kst_6', 'kst_7', 'kst_23', 'kst_25', 'kst_26', 'dmi_6', 'dmi_7', 'dmi_8', 'dmi_9', 'dmi_10', 'dmi_11', 'dmi_12', 'dmi_13', 'dmi_14', 'dmi_15', 'dmi_16', 'dmi_17', 'dmi_18', 'dmi_19', 'dmi_20', 'dmi_21', 'dmi_22', 'dmi_23', 'dmi_24', 'dmi_25', 'dmi_26', 'bb_6', 'bb_7', 'bb_8', 'bb_9', 'bb_10', 'bb_11', 'bb_12', 'bb_13', 'bb_14', 'bb_15', 'bb_16', 'bb_17', 'bb_18', 'bb_19', 'bb_20', 'bb_21', 'bb_22', 'bb_23', 'bb_24', 'bb_25', 'bb_26', 'fi_6', 'fi_7', 'fi_8', 'fi_9', 'fi_10', 'fi_11', 'fi_12', 'fi_13', 'fi_14', 'fi_15', 'fi_16', 'fi_17', 'fi_18', 'fi_19', 'fi_20', 'fi_21', 'fi_22', 'fi_23', 'fi_24', 'fi_25', 'fi_26', 'rsv_6', 'kdjk_6', 'rsv_7', 'kdjk_7', 'rsv_8', 'kdjk_8', 'rsv_9', 'kdjk_9', 'rsv_10', 'kdjk_10', 'rsv_11', 'kdjk_11', 'rsv_12', 'kdjk_12', 'rsv_13', 'kdjk_13', 'rsv_14', 'kdjk_14', 'rsv_15', 'kdjk_15', 'rsv_16', 'kdjk_16', 'rsv_17', 'kdjk_17', 'rsv_18', 'kdjk_18', 'rsv_19', 'kdjk_19', 'rsv_20', 'kdjk_20', 'rsv_21', 'kdjk_21', 'rsv_22', 'kdjk_22', 'rsv_23', 'kdjk_23', 'rsv_24', 'kdjk_24', 'rsv_25', 'kdjk_25', 'rsv_26', 'kdjk_26', 'eom_6', 'eom_7', 'eom_8', 'eom_9', 'eom_10', 'eom_11', 'eom_12', 'eom_13', 'eom_14', 'eom_15', 'eom_16', 'eom_17', 'eom_18', 'eom_19', 'eom_20', 'eom_21', 'eom_22', 'eom_23', 'eom_24', 'eom_25', 'eom_26')\n",
      "[  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
      "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
      "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
      "  91  92  93  94  95  96  97  98  99 100 102 103 104 105 106 107 108 109\n",
      " 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127\n",
      " 128 129 130 131 132 154 160 161 212 218 221 223 224 229 237 239 240 242\n",
      " 243 248 249 250 252 253 254 256 258 259 260 261 262 263 264 265 266 267\n",
      " 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285\n",
      " 286 287 289 290 291 292 293 296 299 300 301 317 319 320 321 322 323 324\n",
      " 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342\n",
      " 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360\n",
      " 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378\n",
      " 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396\n",
      " 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414\n",
      " 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432\n",
      " 433 434 435 436 437 438 439 440 441 442 443 444 445 446]\n",
      "Wall time: 8.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from operator import itemgetter\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "\n",
    "if selection_method == 'anova' or selection_method == 'all':\n",
    "    select_k_best = SelectKBest(f_classif, k=topk)\n",
    "    if selection_method != 'all':\n",
    "        x_train = select_k_best.fit_transform(x_main, y_train)\n",
    "        x_cv = select_k_best.transform(x_cv)\n",
    "        x_test = select_k_best.transform(x_test)\n",
    "    else:\n",
    "        select_k_best.fit(x_main, y_train)\n",
    "    \n",
    "    selected_features_anova = itemgetter(*select_k_best.get_support(indices=True))(list_features)\n",
    "    print(selected_features_anova)\n",
    "    print(select_k_best.get_support(indices=True))\n",
    "    print(\"****************************************\")\n",
    "    \n",
    "if selection_method == 'mutual_info' or selection_method == 'all':\n",
    "    select_k_best = SelectKBest(mutual_info_classif, k=topk)\n",
    "    if selection_method != 'all':\n",
    "        x_train = select_k_best.fit_transform(x_main, y_train)\n",
    "        x_cv = select_k_best.transform(x_cv)\n",
    "        x_test = select_k_best.transform(x_test)\n",
    "    else:\n",
    "        select_k_best.fit(x_main, y_train)\n",
    "\n",
    "    selected_features_mic = itemgetter(*select_k_best.get_support(indices=True))(list_features)\n",
    "    print(len(selected_features_mic), selected_features_mic)\n",
    "    print(select_k_best.get_support(indices=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common selected featues 285 ['roc_19', 'dpo_9', 'mfi_16', 'kst_26', 'cmo_17', 'dpo_20', 'fi_14', 'cci_26', 'rsv_19', 'wr_13', 'rsv_25', 'eom_16', 'wr_18', 'rsi_22', 'kdjk_22', 'cmo_18', 'adjusted_close', 'cci_15', 'wr_26', 'cci_14', 'mfi_25', 'dpo_10', 'cci_16', 'wr_9', 'rsv_15', 'roc_9', 'dmi_22', 'wr_10', 'fi_15', 'cmf_25', 'wr_7', 'roc_12', 'mfi_10', 'rsi_25', 'rsi_15', 'kdjk_9', 'rsi_19', 'rsi_26', 'cmo_21', 'eom_24', 'fi_11', 'rsv_10', 'wr_6', 'roc_15', 'mfi_14', 'fi_10', 'mfi_20', 'dmi_24', 'wr_23', 'roc_24', 'cci_18', 'rsv_20', 'cci_9', 'fi_18', 'rsv_9', 'kdjk_11', 'fi_13', 'wr_8', 'eom_7', 'cmo_7', 'cmf_21', 'kdjk_26', 'dmi_18', 'wr_14', 'cmo_9', 'cmo_22', 'fi_26', 'cmo_25', 'mfi_23', 'roc_7', 'cmf_6', 'fi_23', 'kdjk_10', 'rsv_22', 'kdjk_7', 'kdjk_21', 'cci_13', 'dmi_17', 'roc_11', 'kdjk_17', 'trix_12', 'rsv_8', 'roc_13', 'cmo_6', 'fi_21', 'trix_8', 'roc_17', 'rsi_8', 'cmf_12', 'kdjk_13', 'dmi_9', 'cci_6', 'cci_25', 'eom_13', 'rsi_23', 'mfi_11', 'dmi_13', 'wr_19', 'mfi_9', 'cmf_23', 'cmo_13', 'cci_7', 'cmo_23', 'roc_20', 'kdjk_23', 'rsi_14', 'rsv_13', 'rsi_16', 'dpo_17', 'trix_17', 'kdjk_25', 'rsi_20', 'dmi_26', 'rsv_16', 'mfi_13', 'cci_21', 'eom_12', 'mfi_24', 'roc_23', 'cmf_14', 'cmf_8', 'kdjk_19', 'rsi_12', 'mfi_17', 'dmi_19', 'roc_16', 'cci_19', 'hma_2', 'cci_8', 'kst_25', 'mfi_7', 'rsv_6', 'rsv_11', 'close', 'fi_25', 'dmi_12', 'eom_18', 'cmo_14', 'trix_9', 'kdjk_15', 'rsi_9', 'dpo_14', 'rsv_23', 'wr_17', 'cmo_19', 'fi_16', 'dmi_20', 'dpo_12', 'wr_16', 'dpo_6', 'rsv_21', 'kst_7', 'dmi_10', 'kst_23', 'cci_12', 'cci_17', 'cci_10', 'eom_26', 'cmf_9', 'dmi_7', 'cmo_8', 'mfi_6', 'cmo_12', 'rsv_17', 'eom_8', 'kdjk_8', 'cmf_20', 'eom_15', 'cmo_10', 'fi_22', 'rsv_14', 'kdjk_24', 'roc_18', 'dpo_13', 'wr_12', 'eom_10', 'roc_22', 'cmf_24', 'cmo_24', 'eom_21', 'kdjk_12', 'cmo_20', 'roc_14', 'wr_25', 'cmf_11', 'eom_14', 'kdjk_14', 'wr_15', 'cmf_19', 'fi_19', 'eom_6', 'rsi_17', 'roc_21', 'low', 'rsi_6', 'cmo_15', 'dmi_8', 'rsi_18', 'dmi_25', 'mfi_12', 'eom_22', 'dpo_8', 'mfi_22', 'fi_12', 'cmo_26', 'cci_24', 'cci_22', 'fi_7', 'eom_25', 'rsi_24', 'mfi_21', 'cmf_16', 'dpo_7', 'fi_24', 'rsv_7', 'eom_9', 'cci_11', 'dpo_11', 'fi_17', 'rsv_12', 'rsi_13', 'kdjk_6', 'rsi_11', 'rsv_24', 'cci_20', 'eom_19', 'high', 'dmi_6', 'wr_22', 'cmf_26', 'cmo_16', 'trix_18', 'wr_11', 'mfi_18', 'roc_10', 'wr_24', 'trix_11', 'fi_9', 'rsv_18', 'mfi_19', 'cmf_10', 'eom_20', 'fi_6', 'rsv_26', 'cmf_15', 'kst_6', 'wr_21', 'fi_20', 'cci_23', 'kdjk_20', 'dpo_26', 'eom_17', 'mfi_26', 'cmf_7', 'roc_26', 'cmo_11', 'dpo_19', 'cmf_18', 'kdjk_16', 'volume', 'rsi_10', 'eom_23', 'dmi_14', 'dmi_16', 'dmi_23', 'cmf_13', 'dpo_23', 'dpo_16', 'wr_20', 'rsi_7', 'dmi_21', 'rsi_21', 'mfi_15', 'roc_25', 'kdjk_18', 'roc_6', 'mfi_8', 'eom_11', 'dpo_18', 'dmi_15', 'trix_6', 'roc_8', 'cmf_22', 'fi_8', 'dmi_11']\n",
      "[2, 3, 4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 58, 59, 62, 63, 64, 65, 66, 67, 70, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 90, 92, 93, 95, 96, 98, 100, 103, 104, 105, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 218, 239, 240, 243, 248, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 290, 293, 301, 317, 319, 320, 322, 323, 324, 325, 327, 328, 332, 333, 334, 335, 337, 339, 340, 341, 364, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 406, 407, 410, 411, 412, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 425, 426, 427, 428, 429, 430, 432, 433, 434, 435, 436, 438, 441, 442, 444, 445, 446]\n"
     ]
    }
   ],
   "source": [
    "if selection_method == 'all':\n",
    "    common = list(set(selected_features_anova).intersection(selected_features_mic))\n",
    "    print(\"common selected featues\", len(common), common)\n",
    "    if len(common) < num_features:\n",
    "        raise Exception('number of common features found {} < {} required features. Increase \"topk variable\"'.format(len(common), num_features))\n",
    "    feat_idx = []\n",
    "    for c in common:\n",
    "        feat_idx.append(list_features.index(c))\n",
    "    feat_idx = sorted(feat_idx[0:225])\n",
    "    print(feat_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x, y train/cv/test (2797, 225) (2797,) (1200, 225) (1200,) (1000, 225) (1000,)\n"
     ]
    }
   ],
   "source": [
    "if selection_method == 'all':\n",
    "    x_train = x_train[:, feat_idx]\n",
    "    x_cv = x_cv[:, feat_idx]\n",
    "    x_test = x_test[:, feat_idx]\n",
    "\n",
    "print(\"Shape of x, y train/cv/test {} {} {} {} {} {}\".format(x_train.shape, \n",
    "                                                             y_train.shape, x_cv.shape, y_cv.shape, x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of class 0 = 6.399713979263496, class 1 = 6.149445834823024\n"
     ]
    }
   ],
   "source": [
    "_labels, _counts = np.unique(y_train, return_counts=True)\n",
    "print(\"percentage of class 0 = {}, class 1 = {}\".format(_counts[0]/len(y_train) * 100, _counts[1]/len(y_train) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nayak\\Miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\nayak\\Miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\nayak\\Miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\nayak\\Miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\nayak\\Miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\nayak\\Miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\nayak\\Miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\nayak\\Miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\nayak\\Miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\nayak\\Miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\nayak\\Miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\nayak\\Miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "\n",
    "def get_sample_weights(y):\n",
    "    \"\"\"\n",
    "    calculate the sample weights based on class weights. Used for models with\n",
    "    imbalanced data and one hot encoding prediction.\n",
    "\n",
    "    params:\n",
    "        y: class labels as integers\n",
    "    \"\"\"\n",
    "\n",
    "    y = y.astype(int)  # compute_class_weight needs int labels\n",
    "    class_weights = compute_class_weight('balanced', np.unique(y), y)\n",
    "    \n",
    "    print(\"real class weights are {}\".format(class_weights), np.unique(y))\n",
    "    print(\"value_counts\", np.unique(y, return_counts=True))\n",
    "    sample_weights = y.copy().astype(float)\n",
    "    for i in np.unique(y):\n",
    "        sample_weights[sample_weights == i] = class_weights[i]  # if i == 2 else 0.8 * class_weights[i]\n",
    "        # sample_weights = np.where(sample_weights == i, class_weights[int(i)], y_)\n",
    "\n",
    "    return sample_weights\n",
    "\n",
    "def reshape_as_image(x, img_width, img_height):\n",
    "    x_temp = np.zeros((len(x), img_height, img_width))\n",
    "    for i in range(x.shape[0]):\n",
    "        # print(type(x), type(x_temp), x.shape)\n",
    "        x_temp[i] = np.reshape(x[i], (img_height, img_width))\n",
    "\n",
    "    return x_temp\n",
    "\n",
    "def f1_weighted(y_true, y_pred):\n",
    "    y_true_class = tf.math.argmax(y_true, axis=1, output_type=tf.dtypes.int32)\n",
    "    y_pred_class = tf.math.argmax(y_pred, axis=1, output_type=tf.dtypes.int32)\n",
    "    conf_mat = tf.math.confusion_matrix(y_true_class, y_pred_class)  # can use conf_mat[0, :], tf.slice()\n",
    "    # precision = TP/TP+FP, recall = TP/TP+FN\n",
    "    rows, cols = conf_mat.get_shape()\n",
    "    size = y_true_class.get_shape()[0]\n",
    "    precision = tf.constant([0, 0, 0])  # change this to use rows/cols as size\n",
    "    recall = tf.constant([0, 0, 0])\n",
    "    class_counts = tf.constant([0, 0, 0])\n",
    "\n",
    "    def get_precision(i, conf_mat):\n",
    "        print(\"prec check\", conf_mat, conf_mat[i, i], tf.reduce_sum(conf_mat[:, i]))\n",
    "        precision[i].assign(conf_mat[i, i] / tf.reduce_sum(conf_mat[:, i]))\n",
    "        recall[i].assign(conf_mat[i, i] / tf.reduce_sum(conf_mat[i, :]))\n",
    "        tf.add(i, 1)\n",
    "        return i, conf_mat, precision, recall\n",
    "\n",
    "    def tf_count(i):\n",
    "        elements_equal_to_value = tf.equal(y_true_class, i)\n",
    "        as_ints = tf.cast(elements_equal_to_value, tf.int32)\n",
    "        count = tf.reduce_sum(as_ints)\n",
    "        class_counts[i].assign(count)\n",
    "        tf.add(i, 1)\n",
    "        return count\n",
    "\n",
    "    def condition(i, conf_mat):\n",
    "        return tf.less(i, 3)\n",
    "\n",
    "    i = tf.constant(3)\n",
    "    i, conf_mat = tf.while_loop(condition, get_precision, [i, conf_mat])\n",
    "\n",
    "    i = tf.constant(3)\n",
    "    c = lambda i: tf.less(i, 3)\n",
    "    b = tf_count(i)\n",
    "    tf.while_loop(c, b, [i])\n",
    "\n",
    "    weights = tf.math.divide(class_counts, size)\n",
    "    numerators = tf.math.multiply(tf.math.multiply(precision, recall), tf.constant(2))\n",
    "    denominators = tf.math.add(precision, recall)\n",
    "    f1s = tf.math.divide(numerators, denominators)\n",
    "    weighted_f1 = tf.reduce_sum(f.math.multiply(f1s, weights))\n",
    "    return weighted_f1\n",
    "\n",
    "def f1_metric(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    this calculates precision & recall \n",
    "    \"\"\"\n",
    "\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))  # mistake: y_pred of 0.3 is also considered 1\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    # y_true_class = tf.math.argmax(y_true, axis=1, output_type=tf.dtypes.int32)\n",
    "    # y_pred_class = tf.math.argmax(y_pred, axis=1, output_type=tf.dtypes.int32)\n",
    "    # conf_mat = tf.math.confusion_matrix(y_true_class, y_pred_class)\n",
    "    # tf.Print(conf_mat, [conf_mat], \"confusion_matrix\")\n",
    "\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
    "\n",
    "get_custom_objects().update({\"f1_metric\": f1_metric, \"f1_weighted\": f1_weighted})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real class weights are [5.20856611 5.42054264 0.38116653] [0 1 2]\n",
      "value_counts (array([0, 1, 2]), array([ 179,  172, 2446], dtype=int64))\n",
      "Test sample_weights\n",
      "[2 0 2 0 2 2 2 2 2 2 1 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[0.38116653 5.20856611 0.38116653 5.20856611 0.38116653 0.38116653\n",
      " 0.38116653 0.38116653 0.38116653 0.38116653 5.42054264 0.38116653\n",
      " 0.38116653 5.42054264 0.38116653 0.38116653 0.38116653 0.38116653\n",
      " 0.38116653 0.38116653 0.38116653 0.38116653 0.38116653 0.38116653\n",
      " 0.38116653 0.38116653 0.38116653 0.38116653 0.38116653 0.38116653]\n"
     ]
    }
   ],
   "source": [
    "sample_weights = get_sample_weights(y_train)\n",
    "print(\"Test sample_weights\")\n",
    "rand_idx = np.random.randint(0, 1000, 30)\n",
    "print(y_train[rand_idx])\n",
    "print(sample_weights[rand_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train (2797, 3)\n"
     ]
    }
   ],
   "source": [
    "one_hot_enc = OneHotEncoder(sparse=False, categories='auto')  # , categories='auto'\n",
    "y_train = one_hot_enc.fit_transform(y_train.reshape(-1, 1))\n",
    "print(\"y_train\",y_train.shape)\n",
    "y_cv = one_hot_enc.transform(y_cv.reshape(-1, 1))\n",
    "y_test = one_hot_enc.transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final shape of x, y train/test (2797, 15, 15, 3) (2797, 3) (1000, 15, 15, 3) (1000, 3)\n"
     ]
    }
   ],
   "source": [
    "dim = int(np.sqrt(num_features))\n",
    "x_train = reshape_as_image(x_train, dim, dim)\n",
    "x_cv = reshape_as_image(x_cv, dim, dim)\n",
    "x_test = reshape_as_image(x_test, dim, dim)\n",
    "# adding a 1-dim for channels (3)\n",
    "x_train = np.stack((x_train,) * 3, axis=-1)\n",
    "x_test = np.stack((x_test,) * 3, axis=-1)\n",
    "x_cv = np.stack((x_cv,) * 3, axis=-1)\n",
    "print(\"final shape of x, y train/test {} {} {} {}\".format(x_train.shape, y_train.shape, x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "columns = rows = 3\n",
    "for i in range(1, columns*rows +1):\n",
    "    index = np.random.randint(len(x_train))\n",
    "    img = x_train[index]\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title('image_'+str(index)+'_class_'+str(np.argmax(y_train[index])), fontsize=10)\n",
    "    plt.subplots_adjust(wspace=0.2, hspace=0.2)\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, LeakyReLU\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger, Callback\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.regularizers import l2, l1, l1_l2\n",
    "from tensorflow.keras.initializers import RandomUniform, RandomNormal\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "params = {'batch_size': 80, 'conv2d_layers': {'conv2d_do_1': 0.2, 'conv2d_filters_1': 32, 'conv2d_kernel_size_1': 3, 'conv2d_mp_1': 0, \n",
    "                                               'conv2d_strides_1': 1, 'kernel_regularizer_1': 0.0, 'conv2d_do_2': 0.3, \n",
    "                                               'conv2d_filters_2': 64, 'conv2d_kernel_size_2': 3, 'conv2d_mp_2': 2, 'conv2d_strides_2': 1, \n",
    "                                               'kernel_regularizer_2': 0.0, 'layers': 'two'}, \n",
    "           'dense_layers': {'dense_do_1': 0.3, 'dense_nodes_1': 128, 'kernel_regularizer_1': 0.0, 'layers': 'one'},\n",
    "           'epochs': 3000, 'lr': 0.001, 'optimizer': 'adam'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import *\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "def f1_custom(y_true, y_pred):\n",
    "    y_t = np.argmax(y_true, axis=1)\n",
    "    y_p = np.argmax(y_pred, axis=1)\n",
    "    f1_score(y_t, y_p, labels=None, average='weighted', sample_weight=None, zero_division='warn')\n",
    "\n",
    "def create_model_cnn(params):\n",
    "    model = Sequential()\n",
    "\n",
    "    print(\"Training with params {}\".format(params))\n",
    "    \n",
    "    conv2d_layer1 = Conv2D(params[\"conv2d_layers\"][\"conv2d_filters_1\"],\n",
    "                           params[\"conv2d_layers\"][\"conv2d_kernel_size_1\"],\n",
    "                           strides=params[\"conv2d_layers\"][\"conv2d_strides_1\"],\n",
    "                           kernel_regularizer=regularizers.l2(params[\"conv2d_layers\"][\"kernel_regularizer_1\"]), \n",
    "                           padding='same',activation=\"relu\", use_bias=True,\n",
    "                           kernel_initializer='glorot_uniform',\n",
    "                           input_shape=(x_train[0].shape[0],\n",
    "                                        x_train[0].shape[1], x_train[0].shape[2]))\n",
    "    model.add(conv2d_layer1)\n",
    "    if params[\"conv2d_layers\"]['conv2d_mp_1'] > 1:\n",
    "        model.add(MaxPool2D(pool_size=params[\"conv2d_layers\"]['conv2d_mp_1']))\n",
    "        \n",
    "    model.add(Dropout(params['conv2d_layers']['conv2d_do_1']))\n",
    "    if params[\"conv2d_layers\"]['layers'] == 'two':\n",
    "        conv2d_layer2 = Conv2D(params[\"conv2d_layers\"][\"conv2d_filters_2\"],\n",
    "                               params[\"conv2d_layers\"][\"conv2d_kernel_size_2\"],\n",
    "                               strides=params[\"conv2d_layers\"][\"conv2d_strides_2\"],\n",
    "                               kernel_regularizer=regularizers.l2(params[\"conv2d_layers\"][\"kernel_regularizer_2\"]),\n",
    "                               padding='same',activation=\"relu\", use_bias=True,\n",
    "                               kernel_initializer='glorot_uniform')\n",
    "        model.add(conv2d_layer2)\n",
    "        \n",
    "        if params[\"conv2d_layers\"]['conv2d_mp_2'] > 1:\n",
    "            model.add(MaxPool2D(pool_size=params[\"conv2d_layers\"]['conv2d_mp_2']))\n",
    "        \n",
    "        model.add(Dropout(params['conv2d_layers']['conv2d_do_2']))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(params['dense_layers'][\"dense_nodes_1\"], activation='relu'))\n",
    "    model.add(Dropout(params['dense_layers']['dense_do_1']))\n",
    "\n",
    "    if params['dense_layers'][\"layers\"] == 'two':\n",
    "        model.add(Dense(params['dense_layers'][\"dense_nodes_2\"], activation='relu', \n",
    "                        kernel_regularizer=params['dense_layers'][\"kernel_regularizer_1\"]))\n",
    "        model.add(Dropout(params['dense_layers']['dense_do_2']))\n",
    "\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    if params[\"optimizer\"] == 'rmsprop':\n",
    "        optimizer = optimizers.RMSprop(lr=params[\"lr\"])\n",
    "    elif params[\"optimizer\"] == 'sgd':\n",
    "        optimizer = optimizers.SGD(lr=params[\"lr\"], decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    elif params[\"optimizer\"] == 'adam':\n",
    "        optimizer = optimizers.Adam(learning_rate=params[\"lr\"], beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy', f1_metric])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def check_baseline(pred, y_test):\n",
    "    print(\"size of test set\", len(y_test))\n",
    "    e = np.equal(pred, y_test)\n",
    "    print(\"TP class counts\", np.unique(y_test[e], return_counts=True))\n",
    "    print(\"True class counts\", np.unique(y_test, return_counts=True))\n",
    "    print(\"Pred class counts\", np.unique(pred, return_counts=True))\n",
    "    holds = np.unique(y_test, return_counts=True)[1][2]  # number 'hold' predictions\n",
    "    print(\"baseline acc:\", (holds/len(y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params {'batch_size': 80, 'conv2d_layers': {'conv2d_do_1': 0.2, 'conv2d_filters_1': 32, 'conv2d_kernel_size_1': 3, 'conv2d_mp_1': 0, 'conv2d_strides_1': 1, 'kernel_regularizer_1': 0.0, 'conv2d_do_2': 0.3, 'conv2d_filters_2': 64, 'conv2d_kernel_size_2': 3, 'conv2d_mp_2': 2, 'conv2d_strides_2': 1, 'kernel_regularizer_2': 0.0, 'layers': 'two'}, 'dense_layers': {'dense_do_1': 0.3, 'dense_nodes_1': 128, 'kernel_regularizer_1': 0.0, 'layers': 'one'}, 'epochs': 3000, 'lr': 0.001, 'optimizer': 'adam'}\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x000001E9CBF90F08>\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "model = create_model_cnn(params)\n",
    "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=False)\n",
    "\n",
    "# SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "best_model_path = os.path.join('.', 'best_model_keras')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,\n",
    "                   patience=100, min_delta=0.0001)\n",
    "# csv_logger = CSVLogger(os.path.join(OUTPUT_PATH, 'log_training_batch.log'), append=True)\n",
    "rlp = ReduceLROnPlateau(monitor='val_loss', factor=0.02, patience=20, verbose=1, mode='min',\n",
    "                        min_delta=0.001, cooldown=1, min_lr=0.0001)\n",
    "mcp = ModelCheckpoint(best_model_path, monitor='val_f1_metric', verbose=1,\n",
    "                      save_best_only=True, save_weights_only=False, mode='max', period=1)  # val_f1_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2797 samples, validate on 1200 samples\n",
      "Epoch 1/3000\n",
      "2496/2797 [=========================>....] - ETA: 0s - loss: 0.8679 - acc: 0.3722 - f1_metric: 0.1928    \n",
      "Epoch 00001: val_f1_metric improved from -inf to 0.11669, saving model to .\\best_model_keras\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to create file (unable to open file: name = '.\\best_model_keras', errno = 13, error message = 'Permission denied', flags = 13, o_flags = 302)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    417\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m       \u001b[1;31m# Epochs only apply to `fit`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m       \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m     \u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m       \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    967\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs_since_last_save\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_freq\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'epoch'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 969\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    970\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    971\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_save_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    998\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1000\u001b[1;33m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1001\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1002\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer, save_format)\u001b[0m\n\u001b[0;32m   1209\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1210\u001b[0m     \"\"\"\n\u001b[1;32m-> 1211\u001b[1;33m     \u001b[0msaving\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1213\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer, save_format)\u001b[0m\n\u001b[0;32m    111\u001b[0m           'or using `save_weights`.')\n\u001b[0;32m    112\u001b[0m     hdf5_format.save_model_to_hdf5(\n\u001b[1;32m--> 113\u001b[1;33m         model, filepath, overwrite, include_optimizer)\n\u001b[0m\u001b[0;32m    114\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[1;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tf_gpu\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m                                swmr=swmr)\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tf_gpu\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[1;31m# Open in append mode (read/write).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to create file (unable to open file: name = '.\\best_model_keras', errno = 13, error message = 'Permission denied', flags = 13, o_flags = 302)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(x_train, y_train, epochs=params['epochs'], verbose=1,\n",
    "                            batch_size=64, shuffle=True,\n",
    "                            # validation_split=0.3,\n",
    "                            validation_data=(x_cv, y_cv),\n",
    "                            callbacks=[mcp, rlp, es]\n",
    "                            , sample_weight=sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "InteractiveShell.ast_node_interactivity = \"last\"\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.plot(history.history['f1_metric'])\n",
    "plt.plot(history.history['val_f1_metric'])\n",
    "\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train_loss', 'val_loss', 'f1', 'val_f1'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score, cohen_kappa_score\n",
    "import seaborn as sns\n",
    "\n",
    "model = load_model(best_model_path)\n",
    "test_res = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"keras evaluate=\", test_res)\n",
    "pred = model.predict(x_test)\n",
    "pred_classes = np.argmax(pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "check_baseline(pred_classes, y_test_classes)\n",
    "conf_mat = confusion_matrix(y_test_classes, pred_classes)\n",
    "print(conf_mat)\n",
    "labels = [0,1,2]\n",
    "\n",
    "f1_weighted = f1_score(y_test_classes, pred_classes, labels=None, \n",
    "         average='weighted', sample_weight=None)\n",
    "print(\"F1 score (weighted)\", f1_weighted)\n",
    "print(\"F1 score (macro)\", f1_score(y_test_classes, pred_classes, labels=None, \n",
    "         average='macro', sample_weight=None))\n",
    "print(\"F1 score (micro)\", f1_score(y_test_classes, pred_classes, labels=None, \n",
    "         average='micro', sample_weight=None))  # weighted and micro preferred in case of imbalance\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#cohen-s-kappa --> supports multiclass; ref: https://stats.stackexchange.com/questions/82162/cohens-kappa-in-plain-english\n",
    "print(\"cohen's Kappa\", cohen_kappa_score(y_test_classes, pred_classes))\n",
    "\n",
    "recall = []\n",
    "for i, row in enumerate(conf_mat):\n",
    "    recall.append(np.round(row[i]/np.sum(row), 2))\n",
    "    print(\"Recall of class {} = {}\".format(i, recall[i]))\n",
    "print(\"Recall avg\", sum(recall)/len(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda uninstall pydot\n",
    "# !conda uninstall pydotplus\n",
    "# !conda uninstall graphviz\n",
    "\n",
    "!conda install pydot\n",
    "!conda install pydotplus"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
